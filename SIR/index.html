<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes</h2>
            <hr>
            <h6> 
                <a href="https://xiaokangwei.github.io" target="_blank">Xiaokang Wei</a><sup>1,2</sup>, 
                <a href="https://https://zhuomanliu.tech/" target="_blank">Zhuoman Liu</a><sup>1</sup>,
                <a href="https://www.sd.polyu.edu.hk/aedlab/" target="_blank">Yan Luximon</a><sup>*,1,2</sup></h6>
            <p><sup>1</sup>The Hong Kong Polytechnic University &nbsp;&nbsp; 
                <sup>2</sup>Laboratory for Artificial Intelligence in Design, HKSAR
            (<sup>*</sup>Corresonding author)</p>
            
            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2402.06136.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/XiaokangWei/SIR" role="button"  target="_blank">
                  <i class="fa fa-github-alt"></i> Code</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/XiaokangWei/SIR" role="button">
                    <i class="fa fa-database"></i> Data</a> </p>
              </div>
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button">
                    <i class="fa fa-file"></i> Supplementary </a> </p>
              </div> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- insert video -->
    <section id="teaser-videos">
        <div class="flex-row">
            <figure style="width: 33%; float: left">
                <video class="centered" width="98%" controls muted loop autoplay>
                    <source src="assets/insert_bathroom.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>
            
            <figure style="width: 33%; float: left">
                <video class="centered" width="98%" controls muted loop autoplay>
                    <source src="assets/insert_restroom.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>
            
            <figure style="width: 33%; float: left">
                <video class="centered" width="98%" controls muted loop autoplay>
                    <source src="assets/insert_office.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>
        </div>
    </section>
  

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
          <p class="text-left"> We propose SIR, an efficient method to decompose differentiable shadows for inverse rendering on indoor scenes using multi-view data, addressing the challenges in accurately decomposing the materials and lighting conditions. Unlike previous methods that struggle with shadow fidelity in complex lighting environments, our approach explicitly learns shadows for enhanced realism in material estimation under unknown light positions. Utilizing posed HDR images as input, SIR employs an SDF-based neural radiance field for comprehensive scene representation. Then, SIR integrates a shadow term with a three-stage material estimation approach to improve SVBRDF quality. Specifically, SIR is designed to learn a differentiable shadow, complemented by BRDF regularization, to optimize inverse rendering accuracy. Extensive experiments on both synthetic and real-world indoor scenes demonstrate the superior performance of SIR over existing methods in both quantitative metrics and qualitative analysis. The significant decomposing ability of SIR enables sophisticated editing capabilities like free-view relighting, object insertion, and material replacement.</p>
        </div>
      </div>
    </div>
  </section>
  <br>
  
    <figure style="width: 60%;">
        <a>
            <img width="80%" src="assets/teaser.png">
        </a>
        <p class="caption" style="margin-bottom: 1px;">
        Given a set of posed multi-view HDR images of an indoor scene, SIR successfully disentangle the scene appearance into 3D neural fields of shape, global and spatially-varying illumination, soft shadows, and SVBRDFs, which can produce convincing results for several applications such as novel view synthesis, free-viewpoint relighting, object insertion, and material replacement
        </p>
    </figure>
  
    <figure style="width: 80%; float: center">
      <a>
          <img width="90%" src="assets/model.png" class="centered">
      </a>
      <p class="caption" style="margin-bottom: 1px;">
      Specifically, our model consists of three phases: 1) In phase 1, we sample a ray with direction and spatial point from the given posed HDR images. The geometry network learns the signed distance, and the HDR-radiance network learns radiance. Ray marching is then employed to obtain the surface point. 2) In phase 2, we sample diffuse incoming light from environment maps for learning irradiance. We also calculate the specular incoming light and the pseudo-hard shadow.3) In phase 3, hard shadow Shard is learned using Θh with pseudo ground truth. We then initialize the parameters using the optimized parameters of Θh. Instance-level BRDF regularizers are applied, and the whole rendering equation is optimized to update the soft shadow, albedo, and roughness.
      </p>
    </figure>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">

<code>@inproceedings{@misc{wei2024sir,
      title={SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes}, 
      author={Xiaokang Wei and Zhuoman Liu and Yan Luximon},
      year={2024},
      eprint={2402.06136},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
